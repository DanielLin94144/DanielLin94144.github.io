---
permalink: /
title: "About Guan-Ting (Daniel) Lin"
excerpt: "About Guan-Ting (Daniel) Lin"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
Hi, I am second-year Ph.D. student at [Speech Processing and Machine Learning Lab](https://twitter.com/ntu_spml), [National Taiwan University](https://www.ntu.edu.tw/), advised by Prof. [Hung-yi Lee](https://speech.ee.ntu.edu.tw/~hylee/index.html).

My research interest includes: 
* Deep Learning for Speech Processing
* Self-supervised Learning
* Real-world Challenges for Speech Technologies

Recent News
======
* (02/2024) A new pre-print paper [Advancing Large Language Models to Capture Varied Speaking Styles and Respond Properly in Spoken Conversations](https://arxiv.org/abs/2402.12786) is released! 
* (01/2024) Receive IEEE Signal Processing Society Travel Grant for participating ICASSP 2024! 
* (12/2023) Three papers are accepted by [ICASSP 2024](https://2024.ieeeicassp.org/) (one first-author and two co-author). See you in Seoul! 
* (03/2023) Joined Amazon Alexa Speech team as applied scientist intern in 2023 summer @ Seattle. 
* (02/2023) My internship work with Amazon Alexa has been accepted by [ICASSP 2023](https://2023.ieeeicassp.org/)!
* (01/2023) Our paper "On the Utility of Self-supervised Models for Prosody-related Tasks", cooperating with Prof. Nigel Ward of UTEP, won the [Best Paper Award](https://slt2022.org/best-papers.php) of IEEE SLT 2022!
* (09/2022) *SUPERB-prosody* is accepted by [SLT 2022](https://slt2022.org/).
* (07/2022) Receive ISCA Travel Grants for [Interspeech 2022](https://interspeech2022.org/).
* (06/2022) My two first-author papers have been accepted at [Interspeech 2022](https://interspeech2022.org/).

Education
======
* **Ph.D.** in Communication Engineering, Data Science and Smart Networking Group, National Taiwan University
*[2021 - Present]*
  * Advisor: Prof. [Hung-yi Lee](https://speech.ee.ntu.edu.tw/~hylee/index.html)
  * GPA: 4.24/4.3; Ranking: 15/158
  * Transferred from M.S. program in Feb. 2023. 
* **Advanced AI Program**, National Tsing Hua University
*[2020 - 2021]*
  * GPA: 4.3/4.3
* **B.S.** in Biomedical Engineering, National Tsing Hua University
*[2017 - 2021]*
  * GPA: 4.08/4.3; Ranking: 1/45

Publications & Preprints
======
* **Advancing Large Language Models to Capture Varied Speaking Styles and Respond Properly in Spoken Conversations**\\
  <u>Guan-Ting Lin</u>, Cheng-Han Chiang, Hung-yi Lee\\
  *Arxiv preprint*\\
  [paper](https://arxiv.org/abs/2402.12786)
* **Paralinguistics-Enhanced Large Language Modeling of Spoken Dialogue**\\
  <u>Guan-Ting Lin</u>, Prashanth Gurunath Shivakumar, Ankur Gandhe, Chao-Han Huck Yang, Yile Gu, Shalini Ghosh, Andreas Stolcke, Hung-yi Lee, Ivan Bulyko\\
  *ICASSP 2024*\\
  [paper](https://arxiv.org/abs/2312.15316)
* **SpeechDPR: End-to-End Spoken Passage Retrieval for Open-Domain Spoken Question Answering**\\
  Chyi-Jiunn Lin, <u>Guan-Ting Lin</u>, Yung-Sung Chuang, Wei-Lun Wu, Shang-Wen Li, Abdelrahman Mohamed, Hung-yi Lee, Lin-shan Lee\\
  *ICASSP 2024*\\
  [paper](https://arxiv.org/abs/2401.13463)
* **Towards ASR Robust Spoken Language Understanding Through In-Context Learning With Word Confusion Networks**\\
  Kevin Everson, Yile Gu, Huck Yang, Prashanth Gurunath Shivakumar, <u>Guan-Ting Lin</u>, Jari Kolehmainen, Ivan Bulyko, Ankur Gandhe, Shalini Ghosh, Wael Hamza, Hung-yi Lee, Ariya Rastrow, Andreas Stolcke\\
  *ICASSP 2024*\\
  [paper](https://arxiv.org/abs/2401.02921)
* **Improving Textless Spoken Language Understanding with Discrete Units as Intermediate Target**\\
  Guan-Wei Wu<sub>(co-first)</sub>, <u>Guan-Ting Lin</u><sub>(co-first)</sub>, Shang-Wen Li, Hung-yi Lee\\
  *Interspeech 2023*\\
  [paper](https://arxiv.org/abs/2305.18096)
* **Weight-sharing Supernet for Searching Specialized Acoustic Event Classification Networks Across Device Constraints**\\
  <u>Guan-Ting Lin</u>, Qingming Tang, Chieh-Chi Kao, Viktor Rozgic, Chao Wang\\
  *ICASSP 2023*\\
  [paper](https://arxiv.org/abs/2303.10351)
* **Introducing Semantics into Speech Encoders**\\
  Derek Xu, Shuyan Dong, Changhan Wang, Suyoun Kim, Zhaojiang Lin, Akshat Shrivastava, Shang-Wen Li, Liang-Hsuan Tseng, Alexei Baevski, <u>Guan-Ting Lin</u>, Hung-yi Lee, Yizhou Sun, Wei Wang\\
  *ACL 2023*\\
  [paper](https://arxiv.org/abs/2211.08402)
* **On the Utility of Self-supervised Models for Prosody-related Task**\\
  <u>Guan-Ting Lin</u><sub>(co-first)</sub>,  Chi-Luen Feng<sub>(co-first)</sub>, Wei-Ping Huang, Yuan Tseng, Tzu-Han Lin, Chen-An Li, Hung-yi Lee, Nigel G. Ward\\
  *SLT 2022 (**Best Paper Award**)*\\
  [paper](https://arxiv.org/abs/2210.07185) / [code](https://github.com/JSALT-2022-SSL/superb-prosody)
* **Listen, Adapt, Better WER: Source-free Single-utterance Test-time Adaptation for Automatic Speech Recognition**\\
  <u>Guan-Ting Lin</u>, Shang-Wen Li, Hung-Yi Lee\\
  *Interspeech 2022 (Oral)*\\
  [paper](https://arxiv.org/abs/2203.14222) / [code](https://github.com/DanielLin94144/Test-time-adaptation-ASR-SUTA)
* **DUAL: Discrete Spoken Unit Adaptive Learning for Textless Spoken Question Answering**\\
  <u>Guan-Ting Lin</u>, Yung-Sung Chuang, Ho-Lam Chung, Shu-wen Yang, Hsuan-Jui Chen, Shuyan Dong, Shang-Wen Li, Abdelrahman Mohamed, Hung-yi Lee, Lin-shan Lee\\
  *Interspeech 2022 (Poster)*\\
  [paper](https://arxiv.org/abs/2203.04911) / [code](https://github.com/DanielLin94144/DUAL-textless-SQA) 
* **Analyzing the Robustness of Unsupervised Speech Recognition**\\
  <u>Guan-Ting Lin</u><sub>(co-first)</sub>, Chan-Jan Hsu<sub>(co-first)</sub>, Da-Rong Liu, Hung-Yi Lee, Yu Tsao\\
  *ICASSP 2022*\\
  [paper](https://arxiv.org/pdf/2110.03509.pdf) / [code](https://github.com/Splend1d/wav2vec-u-patch)
* **SUPERB: Speech processing Universal PERformance Benchmark**\\
  Shu-wen Yang, Po-Han Chi, Yung-Sung Chuang, Cheng-I Lai, Kushal Lakhotia, Yist Y. Lin, Andy T. Liu, Jiatong Shi, Xuankai Chang, <u>Guan-Ting Lin</u>, Tzu-Hsien Huang, Wei-Cheng Tseng, Ko-tik Lee, Da-Rong Liu, Zili Huang, Shuyan Dong, Shang-Wen Li, Shinji Watanabe, Abdelrahman Mohamed, Hung-yi Lee\\
  *Interspeech 2021*\\
  [paper](https://arxiv.org/pdf/2105.01051) / [code](https://github.com/DanielLin94144/DUAL-textless-SQA)
* **Context-gloss Augmentation for Improving Word Sense Disambiguation**\\
  <u>Guan-Ting Lin</u>, Manuel Giambi\\
  *arXiv preprint arXiv:2110.07174*\\
  [paper](https://arxiv.org/pdf/2110.07174)


Experience
======
* **Applied Scientist II Intern, Amazon Alexa, Seattle, United States**\\
  *[2023/6 - 2023/9]*
  * Speech Recognition LM Research Team
  * Paralinguistics-enhanced Large Language Model on spoken dialogue.

* **Applied Scientist I Intern, Amazon Alexa, Cambridge, United States**\\
  *[2022/7 - 2022/10]*
  * Manager: Chieh-Chi Kao / Mentor: Qingming Tang
  * Develop Once-for-all Network Architecture Search techniques on audio event classification.

* **Visiting Reseacher, 8th JASLT Summer Workshop, Johns Hopkins University, Baltimore, United States**\\
  *[2022/6 - 2022/7]*
  * Work with Prof. [Nigel Ward](https://www.cs.utep.edu/nigel/) on [self-supervised pre-training for prosody](https://arxiv.org/abs/2210.07185). 

* **Summer Research Intern & Research Assistant, National Center for High-Performance Computing, National Applied Research Laboratories**\\
  *[2019/7 - 2020/7]*
  * Advisor: Nan-You Chen
  * Low-dose CT image, denoising reconstructed images by U-NET based deep neural network.

Award
======
* IEEE Signal Processing Society Travel Grant @ ICASSP 2024
* Best paper award @ IEEE SLT 2022
* NTU Elite Doctoral Scholarship
* GICE Elite Doctoral Scholarship with NVIDIA
* ISCA travel grant @ Interspeech 2022
* Appier top-tier conference scholarship
* Dean's list * 3 @ NTHU
* Phi Tau Phi Award @ NTHU
* The Zhu Shun Yi He Qin Scholarship @ NTHU

Services
======
* Reviewer
  * Offical: ISCSLP 2022, ARR 2022/2023/2024, ICASSP 2023/2024, ICLR 2024

<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=7Qw12O7m4eZyJ9EztFY7V_gZbGDuLrM-MTmcSbviX2w&cl=ffffff&w=a"></script>

